---
#
# Copyright (c) 2021-2024 Wind River Systems, Inc.
#
# SPDX-License-Identifier: Apache-2.0
#
# SUB-TASKS DESCRIPTION:
#   Bring up Kubernetes master
#   - Update iptables
#   - Create manifest directory
#   - Enable kubelet service (with default/custom registry)
#   - Run kubeadm init
#   - Prepare admin.conf
#   - Set k8s environment variable for new shell
#   - Prepare Calico config and activate Calico networking
#   - Prepare Multus config and activate Multus networking
#   - Prepare SRIOV config and activate SRIOV networking
#   - Prepare SRIOV device plugin config and activate SRIOV device plugin
#   - Restore Helm charts if the host is bootstrapped in restore mode
#   - Prepare and apply coredns config
#   - Restrict coredns to master node and set anti-affnity (duplex system)
#   - Restrict coredns to 1 pod (simplex system)
#   - Add kubelet service override
#   - Register kubelet with pmond
#   - Reload systemd
#

- name: Setup iptables for Kubernetes
  lineinfile:
    path: /etc/sysctl.d/k8s.conf
    line: "{{ item }}"
    create: yes
  with_items:
    - net.bridge.bridge-nf-call-ip6tables = 1
    - net.bridge.bridge-nf-call-iptables = 1
    - net.ipv4.ip_forward = 1
    - net.ipv6.conf.all.forwarding = 1

- name: Update kernel parameters for iptables
  command: sysctl --system &>/dev/null

- name: Create manifests directory required by kubelet
  file:
    path: /etc/kubernetes/manifests
    state: directory
    mode: 0700

- name: Clear pki directory for kubernetes certificates
  file:
    path: "{{ kubeadm_pki_dir }}"
    state: absent

- name: Setup dictionary of kubernetes certificates to install
  set_fact:
    k8s_pki_files: { ca.crt: "{{k8s_root_ca_cert}}", ca.key: "{{k8s_root_ca_key}}" }
  when: (k8s_root_ca_cert)

- name: Create pki directory for kubernetes certificates
  file:
    path: "{{ kubeadm_pki_dir }}"
    state: directory
    mode: 0755

- block:
  - name: Copy apiserver cert file generated by etcd to kubeadm_pki_dir
    copy:
      src: "/etc/etcd/apiserver-etcd-client.crt"
      dest: "{{ kubeadm_pki_dir }}/apiserver-etcd-client.crt"
      remote_src: yes
      force: yes
      mode: '0644'

  - name: Copy apiserver key file generated by etcd to kubeadm_pki_dir
    copy:
      src: "/etc/etcd/apiserver-etcd-client.key"
      dest: "{{ kubeadm_pki_dir }}/apiserver-etcd-client.key"
      remote_src: yes
      force: yes
      mode: '0600'

  - block:
    - name: Copy kubernetes CA crt file
      copy:
        src: "{{ k8s_pki_files['ca.crt'] }}"
        dest: "{{ kubeadm_pki_dir }}/ca.crt"
        mode: '0644'
        remote_src: yes

    - name: Copy kubernetes CA key file
      copy:
        src: "{{ k8s_pki_files['ca.key'] }}"
        dest: "{{ kubeadm_pki_dir }}/ca.key"
        mode: '0600'
        remote_src: yes
    when: k8s_pki_files is defined
  when: mode != 'restore'

- block:
  - name: Generate private key for kubernetes-ca
    openssl_privatekey:
      path: "{{ kubeadm_pki_dir }}/ca.key"
      type: RSA
      size: 4096
      state: present
      force: true

  - name: Generate CSR for kubernetes-ca
    openssl_csr:
      path: "{{ kubeadm_pki_dir }}/ca.csr"
      privatekey_path: "{{ kubeadm_pki_dir }}/ca.key"
      common_name: starlingx
      basic_constraints:
        - CA:TRUE
        - pathlen:1
      basic_constraints_critical: true
      key_usage:
        - keyCertSign
        - digitalSignature
        - keyEncipherment
      force: true

  - name: Generate self-signed CA certificate for kubernetes-ca
    openssl_certificate:
      path: "{{ kubeadm_pki_dir }}/ca.crt"
      privatekey_path: "{{ kubeadm_pki_dir }}/ca.key"
      csr_path: "{{ kubeadm_pki_dir }}/ca.csr"
      provider: selfsigned
      force: true
  when: k8s_pki_files is undefined

- name: Set kubelet node configuration if single-stack
  set_fact:
    node_ip: "{{ controller_0_cluster_host
                 if system_mode != 'simplex'
                 else cluster_floating_address }}"
  when: not cluster_floating_address_secondary is defined

- name: Set kubelet node configuration if dual-stack
  set_fact:
    node_ip: "{{ controller_0_cluster_host + ',' + controller_0_cluster_host_secondary
                  if system_mode != 'simplex'
                  else cluster_floating_address + ',' + cluster_floating_address_secondary }}"
  when: cluster_floating_address_secondary is defined

- name: Create kubelet override config file
  template:
    src: "kubelet.conf.j2"
    dest: "{{ '/etc/default' if os_release == 'debian' else '/etc/sysconfig' }}/kubelet"

- name: Enable kubelet
  systemd:
    name: kubelet
    enabled: yes

- name: Create kube api server encryption provider config file
  vars:
    aescbc_keys:
      - name: key1
        secret: "{{ lookup('password', '/dev/null chars=ascii_letters length=16') | b64encode }}"
  template:
    src: "encryption-provider.yaml.j2"
    dest: "{{ encryption_provider_config }}"
    mode: 0600
  when: mode == 'bootstrap'

- name: Create default audit policy config
  copy:
    src: "default-audit-policy.yaml"
    dest: "{{ default_audit_policy_config }}"
    mode: 0600

- name: Create extra volumes files
  copy:
    dest: "{{ item.hostPath }}"
    content: "{{ item.content }}"
  when: (item.pathType == 'File') and 'content' in item
  loop: "{{ apiserver_extra_volumes + controllermanager_extra_volumes + scheduler_extra_volumes }}"

- name: Set primary loopback ip for kubeadm configuration
  set_fact:
    loopback_ip: "{{ '127.0.0.1' if ipv6_addressing == False else '::1' }}"

- name: Set apiserver SAN list
  set_fact:
    apiserver_cert_list: "{{ [ cluster_floating_address, loopback_ip ] + apiserver_cert_sans + OAM_addresses_primary }}"

# add secondary to apiserver SAN list
- block:
  - name: Set secondary loopback ip for kubeadm configuration
    set_fact:
      apiserver_cert_list: "{{ apiserver_cert_list + ['127.0.0.1' if ipv6_addressing_secondary == False else '::1'] }}"
    when: ipv6_addressing_secondary is defined

  - name: Add secondary cluster floating address on apiserver SAN list
    set_fact:
      apiserver_cert_list: "{{ apiserver_cert_list + [cluster_floating_address_secondary] }}"
    when: cluster_floating_address_secondary is defined

  - name: Add secondary OAM on apiserver SAN list
    set_fact:
      apiserver_cert_list: "{{ apiserver_cert_list + OAM_addresses_secondary}}"
    when: OAM_addresses_secondary is defined

- name: Add primary mgmt addresses to apiserver san list
  block:
  - name: Get primary management ip addresses
    include_tasks: >-
      roles/common/get_network_addresses_from_sysinv/tasks/get_network_addresses_from_sysinv.yml
    vars:
      network_type: mgmt
      network_stack: primary

  - set_fact:
      primary_mgmt_ip_list:
        - "{{ addresses.floating_address }}"
        - "{{ addresses.controller0_address }}"
        - "{{ addresses.controller1_address }}"

  - set_fact:
      apiserver_cert_list: "{{ apiserver_cert_list + primary_mgmt_ip_list | select }}"

- name: Add secondary mgmt addresses to apiserver san list
  block:
  - name: Get secondary management ip addresses
    include_tasks: >-
      roles/common/get_network_addresses_from_sysinv/tasks/get_network_addresses_from_sysinv.yml
    vars:
      network_type: mgmt
      network_stack: secondary

  - set_fact:
      secondary_mgmt_ip_list:
        - "{{ addresses.floating_address if addresses.floating_address is defined }}"
        - "{{ addresses.controller0_address if addresses.controller0_address is defined }}"
        - "{{ addresses.controller1_address if addresses.controller1_address is defined }}"

  - set_fact:
      apiserver_cert_list: "{{ apiserver_cert_list + secondary_mgmt_ip_list | select }}"

- name: Add primary admin addresses to apiserver san list
  block:
  - name: Get primary admin ip addresses
    include_tasks: >-
      roles/common/get_network_addresses_from_sysinv/tasks/get_network_addresses_from_sysinv.yml
    vars:
      network_type: admin
      network_stack: primary

  - set_fact:
      primary_admin_ip_list:
        - "{{ addresses.floating_address if addresses.floating_address is defined }}"
        - "{{ addresses.controller0_address if addresses.controller0_address is defined }}"
        - "{{ addresses.controller1_address if addresses.controller1_address is defined }}"

  - set_fact:
      apiserver_cert_list: "{{ apiserver_cert_list + primary_admin_ip_list | select }}"

- name: Add secondary admin addresses to apiserver san list
  block:
  - name: Get secondary admin ip addresses
    include_tasks: >-
      roles/common/get_network_addresses_from_sysinv/tasks/get_network_addresses_from_sysinv.yml
    vars:
      network_type: admin
      network_stack: secondary

  - set_fact:
      secondary_admin_ip_list:
        - "{{ addresses.floating_address if addresses.floating_address is defined }}"
        - "{{ addresses.controller0_address if addresses.controller0_address is defined }}"
        - "{{ addresses.controller1_address if addresses.controller1_address is defined }}"

  - set_fact:
      apiserver_cert_list: "{{ apiserver_cert_list + secondary_admin_ip_list | select }}"

- debug:
    msg: "kube-apiserver san list: {{ apiserver_cert_list }}"

- name: Set taint configuration for non-AIO systems
  set_fact:
    kubelet_taints: "[{key: 'node-role.kubernetes.io/control-plane', effect: 'NoSchedule'}]"
  when: system_type != 'All-in-one'

- name: Create Kube admin yaml
  template:
    src: roles/common/files/kubeadm.yaml.j2
    dest: /etc/kubernetes/kubeadm.yaml

# This is being called from both bootstrap and optimized-restore, not to break
# when called from optimized-restore, lets not use network_params.cluster_pod_subnet_primary and
# network_params.cluster_pod_subnet_secondary, instead lets split by comma from cluster_pod_subnet.
- name: Set Calico cluster configuration
  set_fact:
    cluster_network_ipv4: "{{ cluster_pod_subnet.split(',')[0] | ipv4
                            if cluster_pod_subnet.split(',')[0] | ipv4
                            else  cluster_pod_subnet.split(',')[-1] | ipv4
                          }}"
    cluster_network_ipv6: "{{ cluster_pod_subnet.split(',')[0] | ipv6
                            if cluster_pod_subnet.split(',')[0] | ipv6
                            else  cluster_pod_subnet.split(',')[-1] | ipv6
                          }}"

- name: Create Calico config file
  template:
    src: "k8s-{{ kubernetes_long_version }}/calico-cni.yaml.j2"
    dest: /etc/kubernetes/calico.yaml

- name: Create Multus config file
  template:
    src: "k8s-{{ kubernetes_long_version }}/multus-cni.yaml.j2"
    dest: /etc/kubernetes/multus.yaml

- name: Create SRIOV Networking config file
  template:
    src: "k8s-{{ kubernetes_long_version }}/sriov-cni.yaml.j2"
    dest: /etc/kubernetes/sriov-cni.yaml

- name: Create SRIOV device plugin config file
  template:
    src: "k8s-{{ kubernetes_long_version }}/sriov-plugin.yaml.j2"
    dest: /etc/kubernetes/sriovdp-daemonset.yaml

- name: Create coredns config file
  template:
    src: "coredns.yaml.j2"
    dest: /etc/kubernetes/coredns.yaml

- block:
  - name: Restore kubernetes certificates
    shell: tar --use-compress-program=pigz -C / --overwrite -xpf {{ restore_data_file }} {{ item }}
    args:
      warn: false
    with_items:
      - "{{ kubeadm_pki_dir | regex_replace('^\\/', '') }}"
    become_user: root

  - name: Clear certificates generated by k8s when restoring a backup taken from ctrl_1
    file:
      path: "{{ kubeadm_pki_dir }}/{{ item }}"
      state: absent
    with_items:
      - "apiserver.crt"
      - "apiserver.key"
      - "apiserver-kubelet-client.crt"
      - "apiserver-kubelet-client.key"
      - "front-proxy-client.crt"
      - "front-proxy-client.key"
    when: (system_mode == 'duplex') and (backup_taken_from == 'controller-1')

  - name: Restore encryption provider config
    shell: tar --use-compress-program=pigz -C / --overwrite -xpf {{ restore_data_file }} {{ item }}
    args:
      warn: false
    with_items:
      - "{{ encryption_provider_config | regex_replace('^\\/', '') }}"
    become_user: root

  - name: Stop etcd
    service:
      name: etcd
      state: stopped

  - name: Restore etcd database
    include_role:
      name: backup-restore/restore-etcd
    vars:
      platform_backup_fqpn: "{{ restore_data_file }}"

  - name: Start etcd
    service:
      name: etcd
      state: started

  when: mode == 'restore'

- block:
  - name: Set unabortable flag for {{ inventory_hostname }}
    file:
      path: "{{ override_files_dir }}/.{{ inventory_hostname }}_deploy_not_abortable"
      mode: 0644
      group: root
      state: touch

  # To make sure an abort request was not issued right before creating
  # the unabortable flag, we add a small wait time to make sure kubeadm
  # is not going to be aborted.
  - name: Wait 1 second before starting non abortable tasks
    pause:
      seconds: 1

  when: distributed_cloud_role  == 'subcloud'
  delegate_to: localhost

- name: Initializing Kubernetes master
  command: kubeadm init --ignore-preflight-errors=DirAvailable--var-lib-etcd --config=/etc/kubernetes/kubeadm.yaml

- name: Remove unabortable flag for {{ inventory_hostname }}
  file:
    path: "{{ override_files_dir }}/.{{ inventory_hostname }}_deploy_not_abortable"
    state: absent
  when: distributed_cloud_role  == 'subcloud'
  delegate_to: localhost

- name: Update kube admin.conf file mode and owner
  file:
    path: /etc/kubernetes/admin.conf
    mode: 0640
    group: sys_protected

- name: Set up k8s environment variable
  copy:
    src: /usr/share/puppet/modules/platform/files/kubeconfig.sh
    dest: /etc/profile.d/kubeconfig.sh
    remote_src: yes

- name: Set permissions to 600 for all .crt files in /etc/kubernetes/pki
  file:
    path: "{{ item }}"
    mode: '0600'
  with_fileglob:
    - "{{ kubeadm_pki_dir }}/*.crt"

- name: Patch pull secret into kube-proxy service account
  command: >
    kubectl --kubeconfig=/etc/kubernetes/admin.conf patch serviceaccount
    kube-proxy -p '{"imagePullSecrets": [{"name": "registry-local-secret"}]}' -n kube-system

- block:
  - name: Find old local registry secret
    shell: "kubectl --kubeconfig=/etc/kubernetes/admin.conf get secrets -n kube-system |
            grep registry-local-secret | awk '{print $1}'"
    register: old_local_registry_secret

  - name: Delete old local registry secret
    shell: "kubectl --kubeconfig=/etc/kubernetes/admin.conf delete secret -n kube-system registry-local-secret"
    when: old_local_registry_secret.stdout

  - name: Create local registry pull secret
    command: "kubectl --kubeconfig=/etc/kubernetes/admin.conf create secret docker-registry registry-local-secret
              --docker-server={{ local_registry }} --docker-username={{ local_registry_credentials['username'] }}
              --docker-password={{ local_registry_credentials['password'] }} -n kube-system"

  - name: Activate Calico Networking
    command: "kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f /etc/kubernetes/calico.yaml"
    retries: 5
    delay: 3
    register: result
    until: result.rc == 0

  - name: Activate Multus Networking
    command: "kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f /etc/kubernetes/multus.yaml"

  - name: Activate SRIOV Networking
    command: "kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f /etc/kubernetes/sriov-cni.yaml"

  - name: Activate SRIOV device plugin
    command: "kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f /etc/kubernetes/sriovdp-daemonset.yaml"

  - name: Apply coredns config
    command: "kubectl --kubeconfig=/etc/kubernetes/admin.conf apply -f /etc/kubernetes/coredns.yaml"

    # Restrict coredns to master node and use anti-affinity for core dns for duplex systems
  - block:
    - name: Restrict coredns to master node
      command: >-
        kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system patch deployment coredns -p
        '{"spec":{"template":{"spec":{"nodeSelector":{"node-role.kubernetes.io/control-plane":""}}}}}'

    - name: Use anti-affinity for coredns pods
      command: >-
        kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system patch deployment coredns -p
        '{"spec":{"template":{"spec":{"affinity":{"podAntiAffinity":{"requiredDuringSchedulingIgnoredDuringExecution":[{"labelSelector":{"matchExpressions":[{"key":"k8s-app","operator":"In","values":["kube-dns"]}]},"topologyKey":"kubernetes.io/hostname"}]}}}}}}'
    when: system_mode != 'simplex'

  - name: Restrict coredns to 1 pod for simplex
    command: kubectl --kubeconfig=/etc/kubernetes/admin.conf -n kube-system scale --replicas=1 deployment coredns
    when: system_mode == 'simplex'

  when: mode == 'bootstrap'

- block:
  - name: Applying kubernetes plugins
    include_role:
      name: bootstrap/plugins
      tasks_from: "{{ item }}"
    with_items: "{{ k8s_plugins }}"

  - name: Create kube plugin list file
    copy:
      content: "{{ k8s_plugins }}"
      dest: "{{ config_permdir }}/enabled_kube_plugins"
      mode: 0640
      group: sys_protected
  when: k8s_plugins and mode == 'bootstrap'

- name: Add kubelet service override
  copy:
    src: "{{ kubelet_override_template }}"
    dest: /etc/systemd/system/kubelet.service.d/kube-stx-override.conf
    mode: preserve
    remote_src: yes

- name: Add kubelet service cpushares
  ini_file:
    dest: /etc/systemd/system/kubelet.service.d/kubelet-cpu-shares.conf
    section: Service
    option: Slice
    value: k8splatform.slice
    create: true

- name: Register kubelet with pmond
  copy:
    src: "{{ kubelet_pmond_template }}"
    dest: /etc/pmon.d/kubelet.conf
    mode: preserve
    remote_src: yes

- name: Reload systemd
  command: systemctl daemon-reload

- name: Verify systemctl running without timeout
  import_role:
    name: common/verify-systemctl-running

- name: Create persistent certificate directory
  file:
    path: "{{ config_permdir }}/kubernetes/pki/"
    state: directory
    mode: 0700

- name: Copy certificates
  copy:
    src: "{{ kubeadm_pki_dir }}/{{ item }}"
    dest: "{{ config_permdir }}/kubernetes/pki/"
    remote_src: yes
    force: yes
    mode: 0700
  with_items:
    - ca.crt
    - ca.key
    - sa.pub
    - sa.key
    - front-proxy-ca.crt
    - front-proxy-ca.key

- name: Create controller directory path on the LUKS FS
  file:
    path: "{{ luks_fs_dir }}controller/etc/kubernetes/"
    state: directory
    mode: 0755
  become: true

- name: Check if the kube api server encryption provider config file exists
  stat:
    path: "{{ encryption_provider_config }}"
  register: file_info

- name: Move kube api server encryption provider config to LUKS FS if it exists and is not a symbolic link
  command: >-
    mv "{{ encryption_provider_config }}" "{{ luks_fs_dir }}controller/etc/kubernetes/"
  when: file_info.stat.exists and not file_info.stat.islnk
  become: true

- name: Create symbolic link of encryption-provider.yaml
  file:
    src: "{{ luks_fs_dir }}controller/etc/kubernetes/encryption-provider.yaml"
    dest: "{{ encryption_provider_config }}"
    owner: root
    group: root
    state: link
  become: true

- name: Copy default audit policy config
  copy:
    src: "{{ default_audit_policy_config }}"
    dest: "{{ config_permdir }}/kubernetes/"
    remote_src: yes
    force: yes
    mode: 0400

- name: Copy kubernetes extra volumes config files
  copy:
    src: "{{ item.hostPath }}"
    dest: "{{ config_permdir }}/kubernetes/"
    remote_src: yes
    force: yes
    mode: 0400
  when: (item.pathType == 'File') and (item.name != 'encryption-config')
  loop: "{{ apiserver_extra_volumes + controllermanager_extra_volumes + scheduler_extra_volumes }}"

# creating the associated service-parameter extra-volumes configmaps.
# during restore mode configmaps might exist, so a check is done before
# trying to create new configmaps
- block:
  - name: Checking existing kube-apiserver configmaps
    command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf get configmap
        -n kube-system "kube-apiserver-volumes---{{ item.name }}"
    when: (item.pathType == 'File')
    failed_when: false
    loop: "{{ apiserver_extra_volumes }}"
    register: existent_configmaps

  - name: Create kube-apiserver extra volumes configmaps from config files
    command: >
      kubectl --kubeconfig=/etc/kubernetes/admin.conf create
      configmap "kube-apiserver-volumes---{{ item.item.name }}"
      -n kube-system --from-file "{{ item.item.hostPath }}"
    when: item.item.pathType == 'File' and item.rc != 0
    with_items:
      - "{{ existent_configmaps.results }}"

  - name: Checking existing kube-controller-manager configmaps
    command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf get configmap
        -n kube-system "kube-controller-manager-volumes---{{ item.name }}"
    when: (item.pathType == 'File')
    failed_when: false
    loop: "{{ controllermanager_extra_volumes }}"
    register: existent_configmaps

  - name: Create kube-controller-manager extra volumes configmaps from config files
    command: >
      kubectl --kubeconfig=/etc/kubernetes/admin.conf create configmap
      "kube-controller-manager-volumes---{{ item.item.name }}"
      -n kube-system --from-file "{{ item.item.hostPath }}"
    when: item.item.pathType == 'File' and item.rc != 0
    with_items:
      - "{{ existent_configmaps.results }}"

  - name: Checking existing kube-scheduler configmaps
    command: >
        kubectl --kubeconfig=/etc/kubernetes/admin.conf get configmap
        -n kube-system "kube-scheduler-volumes---{{ item.name }}"
    when: (item.pathType == 'File')
    failed_when: false
    loop: "{{ scheduler_extra_volumes }}"
    register: existent_configmaps

  - name: Create kube-scheduler extra volumes configmaps from config files
    command: >
      kubectl --kubeconfig=/etc/kubernetes/admin.conf create
      configmap "kube-scheduler-volumes---{{ item.item.name }}"
      -n kube-system --from-file "{{ item.item.hostPath }}"
    when: item.item.pathType == 'File' and item.rc != 0
    with_items:
      - "{{ existent_configmaps.results }}"

# The following labels are used by pod security admission controller.
# Also was added the label app.starlingx.io/component which is used
# to group applications that are in the kube-system namespace into
# platform cores.
- name: Add labels to the kube-system namespace
  command: kubectl --kubeconfig=/etc/kubernetes/admin.conf
           label --overwrite namespaces kube-system
           pod-security.kubernetes.io/audit-version=latest
           pod-security.kubernetes.io/enforce-version=latest
           pod-security.kubernetes.io/warn-version=latest
           pod-security.kubernetes.io/audit=privileged
           pod-security.kubernetes.io/enforce=privileged
           pod-security.kubernetes.io/warn=privileged
           app.starlingx.io/component=platform

- name: Update system:node clusterrole to get and list namespaces
  command: kubectl --kubeconfig=/etc/kubernetes/admin.conf patch
           clusterrole system:node --type='json'
           --patch='[{"op":"add","path":"/rules/0","value":{"apiGroups":[""],"resources":["namespaces"],"verbs":["get","list"]}}]'

- name: Add system:node:controller-0 as a subject to system:node clusterrolebinding
  command: kubectl --kubeconfig=/etc/kubernetes/admin.conf patch
           clusterrolebinding system:node --type='json'
           --patch='[{"op":"add","path":"/subjects","value":[{"apiGroup":"rbac.authorization.k8s.io","kind":"User","name":"system:node:controller-0"}]}]'

- name: Stop kubelet to mitigate systemd interactions
  systemd:
    name: kubelet
    state: stopped
  retries: 3
  delay: 15

- name: Mark Kubernetes config complete
  file:
    path: /etc/platform/.initial_k8s_config_complete
    state: touch
